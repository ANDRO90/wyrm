{
 "metadata": {
  "name": "ERP Classification"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ERP Classification Example\n",
      "# roughly based on /svn/bbci/toolbox/demos/stdERPclassification.m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.qda import QDA\n",
      "from sklearn import cross_validation\n",
      "\n",
      "from wyrm import processing as proc\n",
      "from wyrm import plot\n",
      "from wyrm import io"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load bv data into cnt\n",
      "cnt = io.load_brain_vision_data('data/OnlineTrainFileVPfaz.vhdr')\n",
      "# remove unneeded channels\n",
      "cnt = proc.remove_channels(cnt, ['EOG.*', 'Mas.*'])\n",
      "# bandpass filter the data\n",
      "cnt = proc.band_pass(cnt, 2, 40)\n",
      "# subsampling to 100hz\n",
      "cnt = proc.subsample(cnt, 100)\n",
      "# epoch the data\n",
      "mrk_def = {'std': ['S %2i' % i for i in range(2, 7)],\n",
      "           'dev': ['S %2i' % i for i in range(12, 17)]\n",
      "           }\n",
      "epo = proc.segment_dat(cnt, mrk_def, [0, 800])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:wyrm.processing:Using fixed order for butterworth filter.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create the feature vector\n",
      "# make sure you don't apply information from the test set to the training set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO: proc_jumping means\n",
      "#epo = proc.jumping_means(epo, [[80, 350], [360, 800]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Simple classification with 50/50 split\n",
      "\n",
      "To create the feature vector we just calculate the variance over the time-axis for each channel and concatenate them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "std = epo.data[epo.axes[0] == 1]\n",
      "dev = epo.data[epo.axes[0] == 0]\n",
      "std_split = std.shape[0] // 2\n",
      "dev_split = dev.shape[0] // 2\n",
      "std1, std2 = std[:std_split], std[std_split:]\n",
      "dev1, dev2 = dev[:dev_split], dev[dev_split:]\n",
      "train = np.append(std1, dev1, axis=0)\n",
      "train = np.var(train, axis=1)\n",
      "#train = train.reshape(train.shape[0], -1)\n",
      "train_labels = np.append(np.zeros(len(std1)), np.ones(len(dev1)))\n",
      "test = np.append(std2, dev2, axis=0)\n",
      "test = np.var(test, axis=1)\n",
      "#test = test.reshape(test.shape[0], -1)\n",
      "test_labels = np.append(np.zeros(len(std2)), np.ones(len(dev2)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# howto use the LDA\n",
      "clf = LDA()\n",
      "# split your data into training and test set\n",
      "# See also: cross validation\n",
      "# train your classifier\n",
      "clf.fit(train, train_labels)\n",
      "# predict your data\n",
      "# clf.predict(data)\n",
      "# get the accuracy for known data\n",
      "print 'LDA Classification Accuracy: %.2f' % clf.score(test, test_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LDA Classification Accuracy: 0.81\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Just for the Lulz: QDA\n",
      "clf = QDA()\n",
      "clf.fit(train, train_labels)\n",
      "print 'QDA Classification Accuracy: %.2f' % clf.score(test, test_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "QDA Classification Accuracy: 0.83\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cross Validation\n",
      "\n",
      "Here we test the 10-fold cross validation for the variance-based classification. The `stratified` means that we make sure the percentage of classes is preserved in the test and training sets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skf = cross_validation.StratifiedKFold(epo.axes[0], 10)\n",
      "for train_i, test_i in skf:\n",
      "    train = epo.data[train_i]\n",
      "    train = np.var(train, axis=1)\n",
      "    #train = train.reshape(train.shape[0], -1)\n",
      "    train_labels = epo.axes[0][train_i]\n",
      "    test = epo.data[test_i]\n",
      "    test = np.var(test, axis=1)\n",
      "    #test = test.reshape(test.shape[0], -1)\n",
      "    test_labels = epo.axes[0][test_i]\n",
      "    clf_lda, clf_qda = LDA(), QDA()\n",
      "    clf_lda.fit(train, train_labels)\n",
      "    clf_qda.fit(train, train_labels)\n",
      "    print 'LDA/QDA Classification Accuracy: %.2f/%.2f' % (clf_lda.score(test, test_labels), clf_qda.score(test, test_labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LDA/QDA Classification Accuracy: 0.83/0.62\n",
        "LDA/QDA Classification Accuracy: 0.83/0.67"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LDA/QDA Classification Accuracy: 0.79/0.63"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LDA/QDA Classification Accuracy: 0.83/0.67"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LDA/QDA Classification Accuracy: 0.82/0.72"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LDA/QDA Classification Accuracy: 0.83/0.71"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LDA/QDA Classification Accuracy: 0.83/0.79"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LDA/QDA Classification Accuracy: 0.80/0.74"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LDA/QDA Classification Accuracy: 0.79/0.70"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LDA/QDA Classification Accuracy: 0.81/0.60"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}