{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Getting the Dataset\n",
      "\n",
      "This example uses the [Data Set 2][bcicomp3ds2] from the BCI Competition 3. After downloading and copying it into a directory called `data` next to this script, you should be able to follow this example.\n",
      "\n",
      "[bcicomp3ds2]: http://www.bbci.de/competition/iii/#data_set_ii\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "from scipy.io import loadmat\n",
      "from matplotlib import pyplot as plt\n",
      "from sklearn import cross_validation\n",
      "from matplotlib import ticker\n",
      "import matplotlib as mpl\n",
      "\n",
      "from wyrm import plot\n",
      "plot.beautify()\n",
      "from wyrm.types import Data\n",
      "from wyrm import processing as proc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TRAIN_A = 'data/BCI_Comp_III_Wads_2004/Subject_A_Train.mat'\n",
      "TRAIN_B = 'data/BCI_Comp_III_Wads_2004/Subject_B_Train.mat'\n",
      "\n",
      "TEST_A = 'data/BCI_Comp_III_Wads_2004/Subject_A_Test.mat'\n",
      "TEST_B = 'data/BCI_Comp_III_Wads_2004/Subject_B_Test.mat'\n",
      "\n",
      "TRUE_LABELS_A = 'WQXPLZCOMRKO97YFZDEZ1DPI9NNVGRQDJCUVRMEUOOOJD2UFYPOO6J7LDGYEGOA5VHNEHBTXOO1TDOILUEE5BFAEEXAW_K4R3MRU'\n",
      "TRUE_LABELS_B = 'MERMIROOMUHJPXJOHUVLEORZP3GLOO7AUFDKEFTWEOOALZOP9ROCGZET1Y19EWX65QUYU7NAK_4YCJDVDNGQXODBEV2B5EFDIDNR'\n",
      "\n",
      "MATRIX = ['abcdef',\n",
      "          'ghijkl',\n",
      "          'mnopqr',\n",
      "          'stuvwx',\n",
      "          'yz1234',\n",
      "          '56789_']\n",
      "\n",
      "MARKER_DEF_TRAIN = {'target': ['target'], 'nontarget': ['nontarget']}\n",
      "MARKER_DEF_TEST = {'flashing': ['flashing']}\n",
      "SEG_IVAL = [0, 600]\n",
      "\n",
      "JUMPING_MEANS_IVALS_A = [200, 250], [220, 260], [310, 375], [350, 400], [430, 490], [550, 600]\n",
      "#JUMPING_MEANS_IVALS_B = [150, 220], [230, 260], [250, 300], [310, 360]\n",
      "#JUMPING_MEANS_IVALS_A = [200, 250], [310, 375], [350, 400], [430, 490], [550, 600]\n",
      "#JUMPING_MEANS_IVALS_B = [150, 220], [250, 300], [310, 360]\n",
      "\n",
      "#Johannes guess\n",
      "#JUMPING_MEANS_IVALS_A = [170, 240], [300, 390], [390, 510]\n",
      "JUMPING_MEANS_IVALS_A = [150, 230], [200, 260], [300, 390], [390, 510]\n",
      "JUMPING_MEANS_IVALS_B = [150, 210], [200, 280], [300, 420]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_dataset(filename):\n",
      "    \"\"\"Load data set and convert it into Wyrm's `Data` format.\n",
      "    \"\"\"\n",
      "    # load the matlab data\n",
      "    data_mat = loadmat(filename)\n",
      "    # load the channel names (the same for all datasets\n",
      "    with open('data/BCI_Comp_III_Wads_2004/eloc64.txt') as fh:\n",
      "        data = fh.read()\n",
      "    channels = []\n",
      "    for line in data.splitlines():\n",
      "        if line:\n",
      "            chan = line.split()[-1]\n",
      "            chan = chan.replace('.', '')\n",
      "            channels.append(chan)\n",
      "    # fix the channel names, some letters have the wrong capitalization\n",
      "    for i, s in enumerate(channels):\n",
      "        s2 = s.upper()\n",
      "        s2 = s2.replace('Z', 'z')\n",
      "        s2 = s2.replace('FP', 'Fp')\n",
      "        channels[i] = s2\n",
      "    # The signal is recorded with 64 channels, bandpass filtered 0.1-60Hz and digitized at 240Hz. The format is Character Epoch x Samples x Channels\n",
      "    data = data_mat['Signal']\n",
      "    data = data.astype('double')\n",
      "    # For each sample: 1 if a row/colum was flashed, 0 otherwise\n",
      "    flashing = data_mat['Flashing'].reshape(-1)\n",
      "    #flashing = np.flatnonzero((np.diff(a) == 1)) + 1\n",
      "    tmp = []\n",
      "    for i, _ in enumerate(flashing):\n",
      "        if i == 0:\n",
      "            tmp.append(flashing[i])\n",
      "            continue\n",
      "        if flashing[i] == flashing[i-1] == 1:\n",
      "            tmp.append(0)\n",
      "            continue\n",
      "        tmp.append(flashing[i])\n",
      "    flashing = np.array(tmp)\n",
      "    # For each sample: 0 when no row/colum was intensified, 1..6 for intensified columns, 7..12 for intensified rows\n",
      "    stimulus_code = data_mat['StimulusCode'].reshape(-1)\n",
      "    stimulus_code = stimulus_code[flashing == 1]\n",
      "    # 0 if no row/col was intensified or the intensified did not contain the target character, 1 otherwise\n",
      "    stimulus_type = data_mat.get('StimulusType', np.array([])).reshape(-1)\n",
      "    # The target characters\n",
      "    target_chars = data_mat.get('TargetChar', np.array([])).reshape(-1)\n",
      "    fs = 240\n",
      "    data = data.reshape(-1, 64)\n",
      "    timeaxis = np.linspace(0, data.shape[0] / fs * 1000, data.shape[0], endpoint=False)\n",
      "    dat = Data(data=data, axes=[timeaxis, channels], names=['time', 'channel'], units=['ms', '#'])\n",
      "    dat.fs = fs\n",
      "    # preparing the markers\n",
      "    target_mask = np.logical_and((flashing == 1), (stimulus_type == 1)) if len(stimulus_type) > 0 else []\n",
      "    nontarget_mask = np.logical_and((flashing == 1), (stimulus_type == 0)) if len(stimulus_type) > 0 else []\n",
      "    flashing = (flashing == 1)\n",
      "    flashing = [[i, 'flashing'] for i in timeaxis[flashing]]\n",
      "    targets = [[i, 'target'] for i in timeaxis[target_mask]]\n",
      "    nontargets = [[i, 'nontarget'] for i in timeaxis[nontarget_mask]]\n",
      "    markers = flashing[:]\n",
      "    markers.extend(targets)\n",
      "    markers.extend(nontargets)\n",
      "    markers.sort()\n",
      "    dat.markers = markers[:]\n",
      "    dat.stimulus_code = stimulus_code\n",
      "    return dat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def preprocess_simple(dat, MRK_DEF, *args, **kwargs):\n",
      "    \"\"\"Simple preprocessing that reaches 97% accuracy.\n",
      "    \"\"\"\n",
      "    fs_n = dat.fs / 2\n",
      "    b, a = proc.signal.butter(5, [10 / fs_n], btype='low')\n",
      "    dat = proc.filtfilt(dat, b, a)\n",
      "   \n",
      "    dat = proc.subsample(dat, 20)\n",
      "    epo = proc.segment_dat(dat, MRK_DEF, SEG_IVAL)\n",
      "    \n",
      "    fv = proc.create_feature_vectors(epo)\n",
      "    return fv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def preprocessing(dat, MRK_DEF, JUMPING_MEANS_IVALS):\n",
      "    fs_n = dat.fs / 2\n",
      "    b, a = proc.signal.butter(16, [30 / fs_n], btype='low')\n",
      "    dat = proc.filtfilt(dat, b, a)\n",
      "    b, a = proc.signal.butter(5, [.4 / fs_n], btype='high')\n",
      "    dat = proc.filtfilt(dat, b, a)\n",
      "    \n",
      "    dat = proc.subsample(dat, 60)\n",
      "    epo = proc.segment_dat(dat, MRK_DEF, SEG_IVAL)\n",
      "    \n",
      "    fv = proc.jumping_means(epo, JUMPING_MEANS_IVALS)\n",
      "    fv = proc.create_feature_vectors(fv)\n",
      "    return fv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "acc = 0\n",
      "for subject in range(2):\n",
      "    if subject == 0:\n",
      "        training_set = TRAIN_A\n",
      "        testing_set = TEST_A\n",
      "        labels = TRUE_LABELS_A\n",
      "        jumping_means_ivals = JUMPING_MEANS_IVALS_A\n",
      "    else:\n",
      "        training_set = TRAIN_B\n",
      "        testing_set = TEST_B\n",
      "        labels = TRUE_LABELS_B\n",
      "        jumping_means_ivals = JUMPING_MEANS_IVALS_B\n",
      "    # load the training set\n",
      "    dat = load_dataset(training_set)\n",
      "    \n",
      "    fv_train = preprocessing(dat, MARKER_DEF_TRAIN, jumping_means_ivals)\n",
      "    # train the lda\n",
      "    clf = proc.lda_train(fv_train)\n",
      "    \n",
      "    # load the testing set\n",
      "    dat = load_dataset(testing_set)\n",
      "    fv_test = preprocessing(dat, MARKER_DEF_TEST, jumping_means_ivals)\n",
      "    # predict\n",
      "    lda_out_prob = proc.lda_apply(fv_test, clf)\n",
      "    \n",
      "    # unscramble the order of stimuli\n",
      "    unscramble_idx = fv_test.stimulus_code.reshape(100, 15, 12).argsort()\n",
      "    static_idx = np.indices(unscramble_idx.shape)\n",
      "    lda_out_prob = lda_out_prob.reshape(100, 15, 12)\n",
      "    lda_out_prob = lda_out_prob[static_idx[0], static_idx[1], unscramble_idx]\n",
      "    \n",
      "    #lda_out_prob = lda_out_prob[:, :5, :]\n",
      "    \n",
      "    # destil the result of the 15 runs\n",
      "    #lda_out_prob = lda_out_prob.prod(axis=1)\n",
      "    lda_out_prob = lda_out_prob.sum(axis=1)\n",
      "        \n",
      "    # \n",
      "    lda_out_prob = lda_out_prob.argsort()\n",
      "    \n",
      "    cols = lda_out_prob[lda_out_prob <= 5].reshape(100, -1)\n",
      "    rows = lda_out_prob[lda_out_prob > 5].reshape(100, -1)\n",
      "    text = ''\n",
      "    for i in range(100):\n",
      "        row = rows[i][-1]-6\n",
      "        col = cols[i][-1]\n",
      "        letter = MATRIX[row][col]\n",
      "        text += letter\n",
      "    print\n",
      "    print 'Result for subject %d' % (subject+1)\n",
      "    print 'Constructed labels: %s' % text.upper()\n",
      "    print 'True labels       : %s' % labels\n",
      "    a = np.array(list(text.upper()))\n",
      "    b = np.array(list(labels))\n",
      "    accuracy = np.count_nonzero(a == b) / len(a)\n",
      "    print 'Accuracy: %.1f%%' % (accuracy * 100)\n",
      "    acc += accuracy\n",
      "print\n",
      "print 'Overal accuracy: %.1f%%' % (100 * acc / 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Result for subject 1\n",
        "Constructed labels: WQXPLZCOMRKO97YFZDEZ1DPI9NNVGRJDJCU2RMEUO1OJD2UFYPOO6J7LDGYEGOA5VHNEHBWXOO1TDOILUEE5BFAEEXAW7K4R3MRU\n",
        "True labels       : WQXPLZCOMRKO97YFZDEZ1DPI9NNVGRQDJCUVRMEUOOOJD2UFYPOO6J7LDGYEGOA5VHNEHBTXOO1TDOILUEE5BFAEEXAW_K4R3MRU\n",
        "Accuracy: 95.0%\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Result for subject 2\n",
        "Constructed labels: SERMIROOMUZJPXJOHUVLEORZP3GLOO5AUFDKEFTVEMOALZOP9ROCGZE11S19CWX65QUYU7NAK_4YCJDVDNGQXODBEV2B5EFDIDNR\n",
        "True labels       : MERMIROOMUHJPXJOHUVLEORZP3GLOO7AUFDKEFTWEOOALZOP9ROCGZET1Y19EWX65QUYU7NAK_4YCJDVDNGQXODBEV2B5EFDIDNR\n",
        "Accuracy: 92.0%\n",
        "\n",
        "Overal accuracy: 93.5%\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Analysis of the data\n",
      "\n",
      "The following part shows how to visualize interesting information of the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, axes = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(9, 6))\n",
      "for idx, file in enumerate([TRAIN_A, TRAIN_B]):\n",
      "    dat = load_dataset(file)\n",
      "    dat = proc.select_channels(dat, [\"fcz\", \"cz\", \"oz\"])\n",
      "    epo = proc.segment_dat(dat, MARKER_DEF_TRAIN, [0, 600])\n",
      "    epo_avg = proc.calculate_classwise_average(epo)\n",
      "    epo = proc.correct_for_baseline(epo, [0, 50])\n",
      "    \n",
      "    for i in range(3):\n",
      "        axes[idx, i].plot(epo_avg.axes[-2], epo_avg.data[..., i].T)\n",
      "        axes[idx, i].grid()\n",
      "\n",
      "for i in range(3):        \n",
      "    axes[0, i].set_title(epo_avg.axes[-1][i])\n",
      "    \n",
      "axes[1, 1].set_xlabel('time [ms]')\n",
      "for i in range(2):\n",
      "    axes[i, 0].set_ylabel(u'voltage [a.u.]')\n",
      "\n",
      "for i in range(2):\n",
      "    axes[i, 2].yaxis.set_label_position(\"right\")\n",
      "    axes[i, 2].set_ylabel('Subject %s' % 'AB'[i])\n",
      "\n",
      "axes[0, -1].legend(epo_avg.class_names)\n",
      "plt.tight_layout()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avgs = [None, None]\n",
      "for idx, file in enumerate([TRAIN_A, TRAIN_B]):\n",
      "    dat = load_dataset(file)\n",
      "    dat = proc.segment_dat(dat, MARKER_DEF_TRAIN, [0, 600])\n",
      "    \n",
      "    dat = proc.calculate_classwise_average(dat)\n",
      "    dat = proc.correct_for_baseline(dat, [0, 50])\n",
      "  \n",
      "    avgs[idx] = dat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_scalps(epo, ivals):\n",
      "    # ratio scalp to colorbar width\n",
      "    scale = 10\n",
      "    dat = proc.jumping_means(epo, ivals)\n",
      "    n_classes = epo.data.shape[0]\n",
      "    n_ivals = len(ivals)\n",
      "    for class_idx in range(n_classes):\n",
      "        vmax = np.abs(dat.data).max()\n",
      "        vmax = round(vmax)\n",
      "        vmin = -vmax\n",
      "        for ival_idx in range(n_ivals):\n",
      "            ax = plt.subplot2grid((n_classes, scale*n_ivals+1), (class_idx, scale*ival_idx), colspan=scale)\n",
      "            plot.ax_scalp(dat.data[class_idx, ival_idx, :], epo.axes[-1], vmin=vmin, vmax=vmax)\n",
      "            if class_idx == 1:\n",
      "                ax.text(0, -1.5, ivals[ival_idx], horizontalalignment='center')\n",
      "            if ival_idx == 0:\n",
      "                ax.text(-1.5, 0, ['nontarget', 'target'][class_idx], color='bm'[class_idx], rotation='vertical', verticalalignment='center')\n",
      "    \n",
      "    # colorbar\n",
      "    ax = plt.subplot2grid((n_classes, scale*n_ivals+1), (0, scale*n_ivals), rowspan=n_classes)\n",
      "    plot.ax_colorbar(vmin, vmax, label='voltage [a.u.]', ticks=[vmin, 0, vmax])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for subj_idx in range(2):\n",
      "    fig = plt.figure(figsize=[(11, 6), (9, 6)][subj_idx])\n",
      "    ivals = [JUMPING_MEANS_IVALS_A, JUMPING_MEANS_IVALS_B][subj_idx]\n",
      "    plot_scalps(avgs[subj_idx], ivals)\n",
      "    plt.tight_layout()\n",
      "    fig.subplots_adjust(left=.06, bottom=.10, right=None, top=None, wspace=0, hspace=0)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epo = [None, None]\n",
      "for idx, file in enumerate([TRAIN_A, TRAIN_B]):\n",
      "    dat = load_dataset(file)\n",
      "    \n",
      "    fs_n = dat.fs / 2\n",
      "    B, A = proc.signal.butter(16, [30 / fs_n], btype='low')\n",
      "    dat = proc.filtfilt(dat, B, A)\n",
      "    B, A = proc.signal.butter(5, [.4 / fs_n], btype='high')\n",
      "    dat = proc.filtfilt(dat, B, A)\n",
      "    dat = proc.subsample(dat, 60)\n",
      "    epo[idx] = proc.segment_dat(dat, MARKER_DEF_TRAIN, [0, 600])\n",
      "    del dat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, axes = plt.subplots(2, 1, sharex=True, sharey=True)\n",
      "for i in range(2):\n",
      "    r2 = proc.calculate_signed_r_square(epo[i])\n",
      "    # switch the sign to make the plot more consistent with the timecourse. This is equivalent to reordering the classidices and calculating r2\n",
      "    r2 *= -1\n",
      "    \n",
      "    max = np.max(np.abs(r2))\n",
      "    im = axes[i].imshow(r2.T, aspect='auto', interpolation='None', vmin=-max, vmax=max)\n",
      "    \n",
      "    axes[i].set_ylabel('%s' % (epo[i].names[-1]))\n",
      "    axes[i].grid()\n",
      "    axes[i].set_title(\"Subject %s\" % \"AB\"[i])\n",
      "    cb = plt.colorbar(im, ax=axes[i])\n",
      "    cb.set_label('[a.u.]')\n",
      "\n",
      "axes[1].yaxis.set_major_formatter(ticker.IndexFormatter(epo[i].axes[-1]))\n",
      "mask = map(lambda x: True if x.lower().endswith('z') else False, epo[i].axes[-1])\n",
      "axes[1].yaxis.set_major_locator(ticker.FixedLocator(np.nonzero(mask)[0]))\n",
      "axes[1].xaxis.set_major_formatter(ticker.IndexFormatter(['%d' % j for j in epo[i].axes[-2]]))\n",
      "axes[1].xaxis.set_major_locator(ticker.MultipleLocator(6))\n",
      "axes[1].set_xlabel('%s [%s]' % (epo[i].names[-2], epo[i].units[-2]))\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}